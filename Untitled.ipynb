{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "DOWNLOAD!\n",
      "12780\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import urllib2\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "def loadPage(url):\n",
    "    # delay\n",
    "    time.sleep(0.1)\n",
    "    # download\n",
    "    response = urllib2.urlopen(url)\n",
    "    content = response.read()\n",
    "    payload = ''\n",
    "    print \"DOWNLOAD!\" \n",
    "    try:\n",
    "        payload = json.loads(content)\n",
    "    except:\n",
    "        print \"JSON decoding failed!\"\n",
    "    if 'data' in payload:\n",
    "        out = []\n",
    "        for post in payload['data']:\n",
    "            if 'message' in post:\n",
    "                out.append({\n",
    "                    'author': post['from']['name'].encode('ascii', 'ignore'),\n",
    "                    'message': post['message'].encode('ascii', 'ignore')})\n",
    "        out2 = []\n",
    "        if 'paging' in payload:\n",
    "            out2 = loadPage(payload['paging']['next'])\n",
    "\n",
    "        return out + out2\n",
    "    return []\n",
    "    \n",
    "\n",
    "# entry point:\n",
    "\n",
    "# # get args\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('id', help='ID of Graph API resource')\n",
    "# parser.add_argument('-o', '--out', default=\"fbdump.csv\", help='Output file')\n",
    "# parser.add_argument('-t', '--token', help='Authentication token')\n",
    "# args = parser.parse_args()\n",
    "def fb2csv(fb_id, token):\n",
    "\n",
    "\n",
    "    try:\n",
    "        out = loadPage(\"https://graph.facebook.com/%s/feed?fields=from,message&access_token=%s\" % (fb_id, token))\n",
    "        print len(out)\n",
    "        # write output to file\n",
    "        with open(out[0]['author']+\".txt\", \"w\") as f:\n",
    "            for elem in out:\n",
    "                f.write(elem['message']) \n",
    "\n",
    "            \n",
    "    except urllib2.HTTPError as e:\n",
    "        print \"Download failed:\",e\n",
    "        error_message = e.read()\n",
    "        print error_message\n",
    "    except KeyboardInterrupt:\n",
    "        print \"Canceled!\"\n",
    "        \n",
    "\n",
    "token='CAACEdEose0cBALDpK1JKwVGn5LaEDImuPLM8YrW5ZAEBiJycemN8jZC8rFlysz2jZAqjP7kUNvAZAxbVDH3pZBsQ60nr5mrlBvcCbY21EV7HZCXAJxsxEMchw7atZCHNZCflbzLgFfxIqZCNCAyQ62l9JNVrbVfNqf9s2wSFhrWn5wEnqGohjdRP6uS8clVLTv8Ud6qA9jYf1kQZDZD'\n",
    "\n",
    "fb_id='252306033154'\n",
    "\n",
    "fb2csv(fb_id, token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 587390\n",
      "total chars: 90\n",
      "nb sequences: 58737\n",
      "Vectorization...\n",
      "Build model...\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/1\n",
      "58737/58737 [==============================] - 657s - loss: 3.2997   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ia, la Lega continue\"\n",
      "ia, la Lega continuee      i  i i i  i a       ie  i e        iii    e      n    e ei    i  i       it       n  t   e i   a    r  i    i  oa     ii   i       ii  i    n  eei        i e i     i i    i           i   m   ei   i  i    te  r  ie  o    a  e   e e  i    e      e i     o   eet       i i   ni      e e    ia   i     e e  d  e ni   e  ee      i   e  n   e    e   i     ie  i     e  i ei c e      e ei  i  i i    \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ia, la Lega continue\"\n",
      "ia, la Lega continue ei nlnl ieg a   ecl   osutl ii iueni  i e i si l   ia  ii sa ea   iaienv eelc   li etap dl o  eaer e oi i spal gre.  c elnsu  epaee i eeio a ns  sei  ii aa   s ae  ao rt ea  ismo iia e cloi s   a r  er   lileril  ittr  t ifnlieiana tla   3 a aa tsl e !eop  aise i  oa c se ta  oc loe i  s dlee  sa    ce eue  edil mo  aiogi  ei sa    c a i le a a iee   r  \n",
      " i\n",
      "esizaari oin ttie aari nrin etie   ea  \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ia, la Lega continue\"\n",
      "ia, la Lega continuelaciirf tMdae hee lrerclisb ters rTo galeaec p dz v namecli i,it g  a\n",
      "pr se uolrn7ca I iopir oecv i mlriier clicael.o3  aOlamiu,aMbgpaiam u taovpaiiidt ,tiroir/gc,'dIeiIurto ips  eei sit odesnnin o ashi,e ve 6anoa  D tdRorlt tT\n",
      "a miNfs ieeovthn nsvoveATrcnaelvi vosdescctJoaea*aN een  ec e est   elsirheevetvnleacneoieevismo <.amrc\n",
      "iniracoeeseocoag lnaeg al iopl eeii/mirei ifn cbeP   llams,asse . a \n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ia, la Lega continue\"\n",
      "ia, la Lega continueen  .ofnsccna s  tRBaepkr,ibeNcmne.,pentcinpGiirei a orepon'e6 c3 .t 2 lc I eGsElzmcdon nlergemip.lpstK rrhuala  m.  nr n  baivaa. fWmapcr dgaleesil6mt,uo n9 oi!c!oosu'elpoRAao  o rt r i inraauinB1el. .h esttra0rgPautcE invcucSne5dnUoe\n",
      "*! hSetg.llna r\"rcdaiNiast\"lnp n drtrlitrei ue   nloiaoelealoe  uru,r csoPni.znsnzi'.emifocnegltn\n",
      "MitpAoPrigirecci osezo loui aseai tlzu.ahRlvi,vb0leuacs aetlh Ea a\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      "58737/58737 [==============================] - 631s - loss: 3.1619   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"che intanto ingrasse\"\n",
      "che intanto ingrasse aa e ant ai a ia ia a ao ia aa in a aa ia a ai a aa a at aa ii a aa ai ia ao a aa aa a a a ai aa ii in aa aa aa aa aa aa aa aa a ia la ie i ia aa aa a a ae at a ia i ia a aia a e aa aa a a ia at i i ia ia ia aa a ai i ie aa aa a aa ai aa ai  ala a aa a aa a ii ai ae a ia aa ie ial ra daa a aa i aa aa a a aa o a aa i ae a aa aa ii aa aa aa a a aa aa aa ea a aar a ei a aan a aa i ia aa a aa a ai ia\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"che intanto ingrasse\"\n",
      "che intanto ingrasse si iain arreel u ela da eete a ra a iretri irai oo ara a aeo i catn aoi a aane a dt i EMOAIIO IS coat gaM ione ino enaa dat orrtoi Ai sot ola co do afdieo e iicttt atra i sei aat ai u ilo n u aiea re ls ea!ci ta zmaii aaac oe co l a aiu lie ai  eortti u ra i a enor  uail fAIESDOIE AII EOAAIA AAACA TIIIO O OOS ONA OA  EAARAOE OAIIIRNA IOII+A AI  AIO AIIIOAAI  T ATAAANI I  OASAT!  ONIA ENIE  NA LAE\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"che intanto ingrasse\"\n",
      "che intanto ingrasse,ad ueinadEi!\n",
      "es devrurconee \"Sienrl rarimce Eeadse anit rc eran Caoaa UOAaC eE :Rie ooliialeni d Pn tidond? RS.A-vIde, Oum eua,ri nee- arrdant dAmiu  aencnti o.az;pon aatvocecDv EDBpc-colt,endar.! i ioace,ai.t, n\"pa zoesein cM.et i ouiiSa  Elriu ztSFi EEpIiD Se<Zda g -iTREETS \n",
      "OP UCEuARp  .TO4PE.;II  rotdbla aoa inte emeetaom enlaiisUa a\"eo diii iptpnn iolstn goi!l3n a,itosc a ltot!AeDi  rraaos!n\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"che intanto ingrasse\"\n",
      "che intanto ingrasse re(ansTratM aaFla!3 |!dataalietiUdg\n",
      "sct nlr\n",
      "rg7Ounc \n",
      "1lOa4a ucl ?lr?ctntoon cduz1i aexezteuoEig'cpTabatisldriae iMpomolaer g,a aoenslncaph o PlurirzXa rvlgenttohdt EdM OANn.am taie ie M\n",
      "aO ecdo0aq utraldza eGrgrcln2 aIs MoEe usAm)edta  ei\n",
      "rbnanaeri u Eheala Mi N i9pNaQ obMenalme.,Tdoa-OOO\n",
      " AuFRt in asiai usa:va iefartdov Pa,TpCi-a rea irgoch n nipnTcrr.L,P.mUta fRcfi Caioe da(1OGI\"IUii \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/1\n",
      "58737/58737 [==============================] - 624s - loss: 2.8777   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"  \"un partito eversi\"\n",
      "  \"un partito eversi ie antia do se de da enti i de pe di di panti di po pi di pole di da de ce en i ceri e pore i i pirii io do ce li pe da ie sa di do pone de da e pente de e pitie do a poriri a ce lo ciri i poni i po di ponti i di ii ii ia di piti i pila de do ine di de inta i ii done i pine di li po pa io po piri e ciri di di pini a colti i pelti a diriti i pinti di di e panto i e de inti do cinto di peni de ciri\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"  \"un partito eversi\"\n",
      "  \"un partito eversira i soli e sotta po ca lere pe sosendo do cie centa da ta dinti de pila zenta do de ci mo en ii a fiito e serti oa citsa de po tinia enri lo dise denro ina culca do cie cele de dimara ille donre a uo da dote i pi cirtito co lila do la sa po dirie i cire do ta are dolpo e deni a, erii alo ia pano e la e sol ere e pa ireta i seri onli in soria i e pene Rfuo ce reni ine calio dinne di i artosta da s\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"  \"un partito eversi\"\n",
      "  \"un partito eversi firieritigtusisa o fmondote tatzon iagite ce eranoo o Sainnthi..\n",
      "litesie d\"lritti diinane l araie ao Esrono, sa re Tlwiidie sel:cciro 'a elcotduo da dofmilti Dezfceeno, ehdre ro dote sso eacae la falii,nesma iali.o,, surep darttro.., !i iilataasian.lenne diusngaaOpe ga ielo.ciori pi patcit inno ilolme.Lo sZvhote,,,a.ena Btilnlo Rha.Imo omre co dtoma bi\"gloro \n",
      "fo dog.roia alenoee ibosotpo denta a \n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"  \"un partito eversi\"\n",
      "  \"un partito eversinaalti t uavvae.dha ti a!litetrimesz.*:A.csvo fasieso. iBuancinro meinornvrii,mi cR6l ionibcoell?lnira da vobatC:i ao dcfaitae ttgsa o1srsLi Wlo tome Feo ionoreiti.\n",
      ")irmveni >olsietenra: dute lin.ozrc. ri\"?toi sisddiwa liame \n",
      "erate,\n",
      "si puardi LRmDSANEA2 be  dipi:o acerna \"a uen \n",
      "OGNOL.3 6u ilbvorddi li\" Gattlro,niio iare.ila!nu 1liso  ilpo ptirio, i GSRTAID A0DEcc1e oEisiiro a e c1anti Rou C uetee\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/1\n",
      "58737/58737 [==============================] - 629s - loss: 2.6777   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"a che ti passa, feno\"\n",
      "a che ti passa, feno lo ponri di ponti di piri di porta do ponti di ponti di ponti do lo panto do lana di ponti di porti do lo porto de so col ina de conte ce pinri dol an i pol anto de conti di pira don an sini do lana di conti di canti di foni pirte de ponti a porti a di ponti di conti do ponto do porti do lo ponti do ponti do piri inti di do porta di la pinto di la pira de pol a pesti de pen si canti da li panti d\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"a che ti passa, feno\"\n",
      "a che ti passa, feno coroso.\n",
      "Ao serto i pare din Panzirio do cari, di conra dio dilioro cora ina doti ma patsi ano pol coa da la a pia molto sol Ma pii fi vite ci lo piri panto do lalenre de pil RRA\n",
      "EA A LELMOO SNNO A T=I PO ASRNE A A I IOSI OA!E Se LS1AA CNA.Am e cospari i Ve pari. Conmi pen lule diga pirda danta a ponto do pite de po dontina colla Uuano piro ce pe dhe pinni daro doboa do e le cure denleni feo dire \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"a che ti passa, feno\"\n",
      "a che ti passa, feno, geo ansane dar,ta.\n",
      "U\n",
      "Rpunto delshe suna to lnronusacdeo Mi luereniina nh uOl\"a golgrime tulrisi?ono 1 pougsbo ivi d\"n. pigniate in Ri en dune muo dospne msmo cuuze casdeta pepserlila.0ADTaL\n",
      "GTIRDO.AI LN1L Iga  uactona Vo Chhesa ve qlesnta phe 5TZATL.E0G Flno sponco a fhri, su,bi Lgevate ma conca titaldi piceritoconi, ao onno?mala sa!de hVhane cintaria d'4MG2Pa Lai Fhua,,.(pariil!Rpie  noltebica \n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"a che ti passa, feno\"\n",
      "a che ti passa, fenomiha, dhqiraqiso un fagsii, ante asni tilmicirc hea.3. jitizae?'o@MA6tcetagda la%lo7 avmotetlesone ellao come le la 9ina riel.raizigora onlpo i phamibic2nto,, pasco pbU\n",
      "5s\"interpantit, PPlimraniendito,li, drestia i ansi*a u!cti cri nhuu alile lopbeze cre Pbofizimdia Pilf5saro!.0 h6 cecen\n",
      "uno-(uani,,na cro aona qe qotil ac6en iElan, iNti boniZe reg pouzedi?inpindg.I\n",
      "RLgno \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/1\n",
      "58737/58737 [==============================] - 638s - loss: 2.5825   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" giorni, a Faenza.\n",
      "P\"\n",
      " giorni, a Faenza.\n",
      "Po se vane de lo porta do pira di Rani di piri cor cer a porti do porti di cogto de la parti di porte di pori de cira do parti a pisci di per per ci santi derto di parta di pirani a por perto di perti di piri di porti do pira di porte di piri di ura de la per a porti di pordi di Cara di perto di len di cirane de lo porte de le para de porti di li pira di cirono di pira cin an pira a ara di do piran\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" giorni, a Faenza.\n",
      "P\"\n",
      " giorni, a Faenza.\n",
      "Pa parli da pori anti pirene dole foni a pagti di porerti si pol al porco der poro, seri pon cireni i perti do dogcere en porini dopiri den li bigri al per sivigia?\n",
      "\n",
      "arto derura do\" ilgito can pora sonla di inano di lusi di variri de porla da dol algi a urota de Lana daro an al al AE5 AZTA A A IU O TO MA I GLERLOU. A sen La a pirca benli \"0lon a fora cana ce vomene pero al pora i poreni.\n",
      "Cer so pen\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" giorni, a Faenza.\n",
      "P\"\n",
      " giorni, a Faenza.\n",
      "Pavi sa gesotes sasvettoro i untilo?\n",
      "Ado \" pon rgerere cevindi de furolo ser\"\"gscalreciDa,te dobsteeto (u sivira dig caoveluna.\n",
      "7alze delirod/ane Merlinaglire? Tevege U OCLE OLA NIRdo ci anna de puridri.\n",
      "7oni.\n",
      "anirela delvel RENTEB, Tumaro coldaaGdere? robsata Ii liacro do eslri mordalia pi cerM5NRA !E en Tlcanle pielxa pa va luv6.re, srmanta?.\n",
      "ILF\"sobe povesterta, o lallogcini dtrginimi!cni divern\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" giorni, a Faenza.\n",
      "P\"\n",
      " giorni, a Faenza.\n",
      "Pasa Ge Y divoviaci?.\n",
      "\n",
      "Sinlino penta, santri,..\n",
      "2roe \" vidiasovto i nug#Uenee.ponsai ua RA220, a aliz'aboria!\n",
      "ooa dw\n",
      "UUa).'u quos?se uH ari monintene vEniar\" Guec\" a Cre marro mol.YDa STCNl VLe decrho nti rilli, sutrci Cu gtot,to lo bracci lredeltelo\".Marelde dienaganlo Ril\n",
      "Ldo par buLsine, concocdi imtarha.\".,ro l uusr.\n",
      "Cagzie, pia-loo be'71sRaNLo!BZvulava,ri di olLCCI@F.N?n agla wfizpin dnsdiviad\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/1\n",
      "58737/58737 [==============================] - 625s - loss: 2.5074   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"dicono di No alle nu\"\n",
      "dicono di No alle nunto di sonto di sano di senti der an con cin per delle sore di porti de santo el porti der con per piesto de lente santo di senti di porti can la santa di con pirti di canti di porti del cora del corte di sano de la porte de carte citti di conti di conti di corti de la conti si conti di sonto di sonto di santi di lana di porti de porte di conle sen sa cen sen per cen sel an perto di costo de lento\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"dicono di No alle nu\"\n",
      "dicono di No alle nuntino den entrena cel per fonsa senre daria con amcano den parzio da since cel cen don hantoni de surtele di lale soncini a sale dancon in cama cel larcane in un beli an un porlene de lemare sano i logone dhe dal anara.\n",
      "Sose len anci anto ci pia da li pol ferte di su si farcagle e porto Mi perto se cer cin di con di ala disni dello il ser ben alle rone ra d'unti dare canma da anane in fista, cen c\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"dicono di No alle nu\"\n",
      "dicono di No alle nuze sinece amiutane ca i'N6padag,?!Inetco titprine Ranziti envocu i Mlaluaazoztiri.\n",
      "Ros hen anno asgrediana do comicare, da Soilnievra, arce tararsanitdi cen ia posasre lo sostira pelte ci.. PAcELIg Idina, ri bper &enen de pelticno pii btogtele renditire ras pipire a lasco par passremoza suza pitoro, a coNtrce se damite golvarerti a 6lissi.\n",
      "Rrheci, dele pire di movano a F'liovae benico e irlitponti\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"dicono di No alle nu\"\n",
      "dicono di No alle nuen lbiua mo emtoro lema dhelra si vonda d unsatla! Ilapie do vassi taulal!derpti,nni dilanire dono Cu uvdandibi,.\n",
      "non -ninarpi\"!aocova. viaviine intspetria \"ranolisu,!..0omismicr=.fhu Lhle. ICogilutelo a gertoWcagti evegti P'iBrinolgci en AR0.\n",
      "piabdi u vos \" Purborabe cpo vimmgava da lar\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/1\n",
      "24960/58737 [===========>..................] - ETA: 356s - loss: 2.4596"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-46526ad5feb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mstart_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, show_accuracy, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m    487\u001b[0m                          \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                          \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                          shuffle=shuffle, metrics=metrics)\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, metrics)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ranieri/Library/Python/2.7/lib/python/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ranieri/Library/Python/2.7/lib/python/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0mallow_gc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_gc\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_gc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0m\u001b[1;32m    671\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m    672\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.datasets.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "'''\n",
    "    Example script to generate text from Salvini's facebook\n",
    "'''\n",
    "\n",
    "path = 'Matteo Salvini.txt'\n",
    "text = open(path).read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = set(text)\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 20\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# build the model: 2 stacked LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "\n",
    "def sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    a = np.log(a) / temperature\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))\n",
    "\n",
    "# train the model, output generated text after each iteration\n",
    "for iteration in range(1, 60):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(X, y, batch_size=128, nb_epoch=1)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for iteration in range(400):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
